DE Edge computing; Ad-hoc edge infrastructure; Admission control; Service
   placement; Resource availability prediction
ID SYSTEMS; PLACEMENT
AB The penetration of connected devices in today's society has reached overwhelming figures particularly in the last decade. At present connected devices are not only becoming available everywhere, but they are rapidly gaining complexity in terms of their ability to hold significant compute and storage capacities. Thus, computing ceases to be confined to certain stationary compute devices in order to allow compute to be embedded and pervasive to everything. This feature combined with the fact that AI processes are multiplying the need for timely processing at the Edge, reveals the urgency to exploit all compute capacity available at the Edge of the network. This represents a significant breakthrough to initial Edge computing developments concentrated in providing low latency compute environments for which IoT devices are solely considered as data sources. Ad-hoc Edge Cloud is a distributed and decentralized Edge computing system dynamically formed out of IoT Edge computing resources, which aims to exploit increasingly available compute capacity at the Edge. The marked characteristics of the IoT devices, which constitute this infrastructure, pose specific challenges to resource management in this context especially due to heterogeneity, dynamicity, and volatility of resources, resulting in the probability of node churn. In this paper , we address particular admission control and service placement issues for Ad-hoc Edge Cloud by presenting a specific Admission Control mechanism for which we define and validate an associated resource availability prediction model. (C) 2020 Elsevier B.V. All rights reserved.