DE Compute unified device architecture (CUDA); graphics processing unit
   (GPU); parallel optimization; timeevolving oceanic surface model (TOSM)
ID RADIATIVE-TRANSFER MODEL; MONTE-CARLO SIMULATIONS; SEA-SURFACE; CLOUD
   MICROPHYSICS; GRAZING-INCIDENCE; DOPPLER-SHIFT; IMPLEMENTATION;
   IDENTIFICATION; ARCHITECTURE; ALGORITHM
AB The development of a time-evolving oceanic surface model (TOSM) is important for the accuracy of determining electromagnetic scattering properties from the sea surface in oceanic remote sensing, target detection, and synthetic aperture radar imagery at arbitrary incident angles, especially small grazing angles. The double superimposition model (DSM) is a well-known approach for TOSM, which is composed of large-scale gravity waves and small-scale capillary ripples superimposed on them. However, due to the real-time dynamic complexity and dimensionality of the TOSM, the traditional DSM algorithm may be very time consuming and hardly meet the real-time requirements. In this paper, the feasibility of using graphics processing units (GPUs) with diverse compute unified device architecture optimization techniques to increase the speed of the generation of the TOSM is investigated. The entirely GPU-based TOSM implemented in this study includes the most effective use of temporary arrays, fast-math compiler options, shared memory, more L1 cache use than shared memory, and page-locked host memory. With respect to single-threaded C programs running on Intel(R) Core(TM) i7-2600K CPU, optimization on the GPU-based generated TOSM can achieve a speedup of 791 x by using a single NVIDIA Tesla K80 GPU model. This new GPU-based TOSM implemented shows great potential for studying the scattering characteristics of electromagnetic backscattered echoes from dynamic sea surfacess.