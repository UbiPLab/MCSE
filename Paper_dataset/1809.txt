DE Fog computing; optimization; resource allocation
AB Offloading computation tasks from resource-poor end devices to powerful backend clouds has become a prevalent solution thanks to the rapid development of cloud computing. However, modern Internet of Things applications, such as augmented reality and real-time monitoring, bring stringent delay requirements to the computation tasks in the device-to-computing-facility communications. To better accommodate the delay requirements of the computation tasks, the recently proposed fog computing architecture suggests that these computation tasks can be extensively offloaded to the distributed computation facilities along the cloud-to-things continuum. These computation facilities, including central clouds and the computation facilities standing at the network edge, jointly form an overlay network, named a fog network, to provide fog computing services for end devices. This paper targets a practical and efficient scheme to schedule tasks with heterogeneous delay sensitivities in a shared fog network. A mathematical model is first constructed to capture the major characteristics of a fog network. The model enforces lexicographic max-min fairness, an enhanced metric compared to conventional max-min fairness. The task offloading problem is modeled as an integer nonlinear program. An efficient and exact solution method is proposed based on problem-specific analysis. Finally, synthesized-trace-driven simulations demonstrate the efficacy of our proposed offloading scheme.