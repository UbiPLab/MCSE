DE Task offloading; Mobile edge computing; Approximation algorithm
ID ALLOCATION; OPTIMIZATION; RESOURCE; REQUESTS; NETWORK
AB With development well underway, 5G is envisioned as an enabler of lighting fast mobile services, such as virtual reality, augmented reality, live video analytics, and etc. In particular, multi-cell Mobile Edge Clouds (MEC) with 5G base stations endowed with computing capability are able to promote the Quality of Services (QoS) of mobile users by executing tasks in the edge cloud. Due to the varying 5G network conditions and limited computation capacity of each base station in the multi-cell MEC, as well as the stringent QoS requirements, a fundamental and challenging problem is how to offload user tasks to the edge cloud, such that the energy consumption of mobile devices is minimized. In this paper, we first formulate the offline and online location-aware mobile task offloading problems in a multi-cell MEC. For the offline location-aware mobile task offloading problem, we then develop an exact solution and an approximation algorithm with an approximation ratio. For the online problem, we thirdly propose a novel deep reinforcement learning-based offloading algorithm for mobile users to obtain the optimal offloading policy. We finally conduct extensive experiments by simulations to evaluate the proposed algorithms against existing benchmarks. The experimental results show that the proposed algorithms are promising and outperform the benchmark algorithms by significantly reducing energy cost of mobile devices and delays experienced by mobile users.