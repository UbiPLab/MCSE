DE Hadoop; Map Reduce; Big data; cloud computing
AB Web has become a prominent storage option of late. But there are certain setbacks in the present web which has a shortfall of appropriate mechanism to create and store artifacts-code, data sets text, image-in digital form which are needed to be unchangeable in any way and be verifiable and permanent. These issues hamper the reliability on the cloud for its functional productivity especially in the domain of science where the re-productivity of outcome process is highly vital. In order to overcome the setbacks, it is proposed a methodology with the stored data processing of encoding and decoding at cloud environment taking the support of cryptographic hash values. In this paper it is presented that how the model work out in verifying the digital artifacts with the help of the format of independent serialization for structured files like nano-publications. It is explained how the documents can be processed using cloud computing environment where the application is integrated with Hadoop installed on Amazon EC2 web service. The approach presented in this work confines to fundamental salient features in the aspect of architecture which is open and decentralized besides completely compatible with prevailing protocols and standards. On its evaluation of approach for its referential implementation exhibits the accomplishment of the design goals indeed stands good practically for the files even larger in size.