DE Activity recognition; feature extraction; local energy; wearable devices
AB Accurate recognition of patients' physical activities leads to correct diagnosis and treatments. However, currently deployed approaches are deficient in recognizing the activities requiring frequent interposture transitions, such as jogging, jumping, turning left, and going upstairs. The reason is that with the change in position and rotation, different activity signals are generated, which are difficult to distinguish from other activities and can therefore mislead the physicians. Therefore, we propose to employ a methodology that utilizes the energy expenditure for each activity and reduces the dimensions of the feature space to differentiate among the activities. In this regard, we employ a feature descriptor called local energy-based shape histogram to preserve the maximum information of local energy. Considering the high volumes of continuously generated data, our methodology integrates cloud computing services with the body area networks. We also investigate the effects of on-body sensors' location on the activity recognition accuracy and also identify the best sensor position for a certain activity with the maximum accuracy. We used the wearable action recognition database dataset to perform the experiments. Our analysis shows that for each activity to be recognized at a decent level, it is imperative to observe the activity recognition performance by simultaneously applying different combinations of sensors.