DE Edge computing; cloud computing; workload allocation; energy efficiency;
   delay guarantee
ID INTERNET
AB Edge computing has recently emerged as an extension to cloud computing for quality of service (QoS) provisioning particularly delay guarantee for delay-sensitive applications. By offloading the computationally intensive workloads to edge servers, the quality of computation experience, e.g., network transmission delay and transmission energy consumption, could be improved greatly. However, the computation resource of an edge server is so scarce that it cannot respond quickly to the bursting computation requirements. Accordingly, queuing delay is un-negligible in a computationally intensive environment, e.g., a computing environment consists of the Internet of Things (IoT) applications. In addition, the computation energy consumption in edge servers may be higher than that in clouds when the workload is heavy. To provide QoS for end users while achieving green computing for computing systems, the cooperation between edge servers and the cloud is significantly important. In this paper, the energy-efficient and delay-guaranteed workload allocation problem in an IoT-edge-cloud computing system are investigated. We formulate a delay-based workload allocation problem which suggests the optimal workload allocations among local edge server, neighbor edge servers, and cloud toward the minimal energy consumption as well as the delay guarantee. The problem is then tackled using a delay-base workload allocation (DBWA) algorithm based on Lyapunov drift-plus-penalty theory. The theoretical analysis and simulation results have been conducted to demonstrate the efficiency of the proposal for energy efficiency and delay guarantee in an IoT-edge-cloud system.