DE Cloud computing; CPU prediction; Neural networks; Optimization;
   Differential Evolution; Particle Swarm Optimization; Covariance Matrix
   Adaptation Evolutionary Strategy; Time series; Neuroevolution
ID PARTICLE SWARM OPTIMIZATION; DIFFERENTIAL EVOLUTION;
   RESOURCE-ALLOCATION; TRAINING ALGORITHM; VIRTUAL MACHINES; TIME;
   ENVIRONMENTS
AB The Infrastructure as a Service (laaS) platform in cloud computing provides resources as a service from a pool of compute, network, and storage resources. One of the major challenges facing cloud computing is to predict the usage of these resources in real time. By knowing future demands, cloud data centres can dynamically scale resources to decrease energy consumption while maintaining a high quality of service. However cloud resource consumption is ever changing, making it difficult for accurate predictions to be produced. This motivates the research presented in this paper which aims to predict in advance the level of CPU consumption of a host. This research implements evolutionary Neural Networks (NN), a powerful machine learning method, to make these predictions. A number of state of the art swarm and evolutionary optimization algorithms are implemented to train the neural networks to predict host utilization: Particle Swarm Optimization (PSO), Differential Evolution (DE) and Covariance Matrix Adaptation Evolutionary Strategy (CMA-ES). The results of this research demonstrate that CMA-ES converges faster to a better solution on the training data. However when evaluated on the test data, DE performs statistically equal to CMA-ES. The results also demonstrate that the trained networks are still accurate when applied to CPU utilization data from different hosts with no further training needed. When evaluated to predict multiple steps into the future, the accuracy of the network understandably decreases but still performs well on average. (C) 2018 Elsevier B.V. All rights reserved.