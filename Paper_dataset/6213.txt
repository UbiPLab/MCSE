AB Emerging availability (and varying complexity and types) of Internet of Things devices, along with the large data volumes that such devices (can potentially) generate, can have a significant impact on our lives, fueling the development of critical next-generation services and applications in a variety of application domains (e.g., health care, smart grids, finance, disaster management, agriculture, transportation, and water management). Deep learning technology, which has been used successfully in computer vision and language modeling, is finding application in new domains driven by the availability of diverse and large datasets. One such example is the advances in medical diagnostics and prediction that use deep learning technology to improve human health. However, timely and reliable transfer of large data streams (a requirement of deep learning technologies for achieving high accuracy) to centralized locations, such as cloud datacenter environments, is being seen as a key limitation of expanding the application horizons of such technologies. To this end, various paradigms, including osmotic computing, have been proposed that promote distribution of data analysis tasks across cloud and edge computing environments. However, these existing paradigms fail to provide a detailed account of how technologies such as deep learning can be orchestrated and take advantage of the cloud, edge, and mobile edge environments in a holistic manner. This Blue Skies piece analyzes the research challenges involved with developing a class of holistic distributed deep learning algorithms that are resource and data aware and are able to account for underlying heterogeneous data models, resource (cloud vs. edge vs. mobile edge) models, and data availability while executing-trading accuracy for execution time, etc.