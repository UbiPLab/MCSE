DE Mobile edge computing; Intelligent resource allocation; Deep
   reinforcement learning; Federated learning
AB With the emergence of a large number of computation-intensive and time-sensitive applications, smart terminal devices with limited resources can only run the model training part of most intelligent applications in the cloud, so a large amount of training data needs to be uploaded to the cloud. This is an important cause of core network communication congestion and poor Quality-of-Experience (QoE) of user. As an important extension and supplement of cloud computing, Mobile Edge Computing (MEC) sinks computing and storage resources from the cloud to the vicinity of User Mobile Devices (UMDs), greatly reducing service latency and alleviating the burden on core networks. However, due to the high cost of edge servers deployment and maintenance, MEC also has the problems of limited network resources and computing resources, and the edge network environment is complex and mutative. Therefore, how to reasonably allocate network resources and computing resources in a changeable MEC environment has become a great aporia. To combat this issue, this paper proposes an intelligent resource allocation model "DRL + FL". Based on this model, an intelligent resource allocation algorithm DDQN-RA based on the emerging DRL algorithm framework DDQN is designed to adaptively allocate network and computing resources. At the same time, the model integrates the FL framework with the mobile edge system to train DRL agents in a distributed way. This model can well solve the problems of uploading large amounts of training data via wireless channels, Non-IID and unbalance of training data when training DRL agents, restrictions on communication conditions, and data privacy. Experimental results show that the proposed "DRL + FL" model is superior to the traditional resource allocation algorithms SDR and LOBO and the intelligent resource allocation algorithm DRLRA in three aspects: minimizing the average energy consumption of the system, minimizing the average service delay, and balancing resource allocation.