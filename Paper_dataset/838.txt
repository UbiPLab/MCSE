DE Face recognition; edge computing; azure iot edge; computation offloading
ID SCHEME; INTERNET
AB With the rapid development of artificial intelligence, face recognition systems are widely used in daily lives. Face recognition applications often need to process large amounts of image data. Maintaining the accuracy and low latency is critical to face recognition systems. After analyzing the two-tier architecture "client-cloud" face recognition systems, it is found that these systems have high latency and network congestion when massive recognition requirements are needed to be responded, and it is very inconvenient and inefficient to deploy and manage relevant applications on the edge of the network. This paper proposes a flexible and efficient edge computing accelerated architecture. By offloading part of the computing tasks to the edge server closer to the data source, edge computing resources are used for image preprocessing to reduce the number of images to be transmitted, thus reducing the network transmission overhead. Moreover, the application code does not need to be rewritten and can be easily migrated to the edge server. We evaluate our schemes based on the open source Azure IoT Edge, and the experimental results show that the three-tier architecture "Client-Edge-Cloud" face recognition system outperforms the state-of-art face recognition systems in reducing the average response time.