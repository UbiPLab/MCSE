DE binary translation; cloud computing; LLVM; floating-point instruction;
   Neon; vector instruction; VFP; virtualization
AB Binary translation attempts to emulate one instruction set with another on the same or different platforms. The important technique is widely used in modern software. Vector and floating-point instructions are widely used in many applications, including multimedia, graphics, and gaming. Although these instructions are usually simulated with software in a binary translator, it is important to support them such that the host single-instruction, multiple-data (SIMD) and floating-point hardware are efficiently used during emulation. We report our design and implementation of the emulation of ARM Neon and vector floating point (VFP) instructions in the machine-code-to-low-level-virtual-machine (MC2LLVM) binary translator. The Neon and VFP instructions are first translated into carefully chosen sequences of LLVM intermediate representation (IR), and later, the IR sequences are optimized and translated into the host native binary by the existing LLVM backend. Because MC2LLVM makes use of the vector and floating-point types in LLVM IR, the generated host native binary can take full advantage of the vector and floating-point functional units, if present, of the host machine. To be fully compliant with Neon and VFP instruction sets, all the features are supported, including the flush-to-zero mode, default not a number mode, and floating-point exceptions. The experimental results show that code generated by MC2LLVM with the Neon and VFP extensions achieves an average speedup of 1.174x in SPEC 2006 benchmark suites and exhibits a floating-point throughput of 12.05x in LINPACK, compared with code generated by MC2LLVM without the Neon and VFP extensions. Furthermore, MC2LLVM is 3.36x faster than QEMU for processing Neon/VFP instructions. Copyright (c) 2016 John Wiley & Sons, Ltd.