DE Compute unified device architecture (CUDA); dimensionality reduction;
   graphics processing units (GPUs); hyperspectral imaging; HySime;
   subspace identification
ID RADIATIVE-TRANSFER MODEL; CLOUD MICROPHYSICS; IMPLEMENTATION; ALGORITHM;
   SCHEME; WRF
AB Signal subspace identification provides a performance improvement in hyperspectral applications, such as target detection, spectral unmixing, and classification. The HySime method is a well-known unsupervised approach for hyperspectral signal subspace identification. It computes the estimated noise and signal correlation matrices from which a subset of eigenvectors is selected to best represent the signal subspace in the least square sense. Depending on the complexity and dimensionality of the hyperspectral scene, the HySime algorithm may be computationally expensive. In this paper, we propose a massively parallel design of the HySime method for acceleration on NVIDIA's graphics processing units (GPUs). Our pure GPU-based implementation includes the optimal use of the page-locked hostmemory, block size, and the number of registers per thread. The proposed implementation was validated in terms of accuracy and performance using the NASA AVIRIS hyperspectral data. The benchmark with the NVIDIA GeForce GTX 580 and Tesla K20 GPUs shows significant speedups with regards to the optimized CPU-based serial counterpart. This new fast implementation of the HySime method demonstrates good potential for real-time hyperspectral applications.