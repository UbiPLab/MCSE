DE Unmanned aerial vehicle (UAV); Structure-from-motion (SfM); Snow depth;
   Dense point cloud; Near real time; Iterative closest point (ICP)
ID WATER EQUIVALENT; MOUNTAIN; UAS
AB A new method for on-demand production of a numerical snow depth map, based on observations carried out in near real time by an unmanned aerial vehicle (UAV), is elaborated. The novelty of the approach resides in the neglection of artificial ground control points (GCPs). The method is based on processing oblique aerial geotagged images of snow-covered terrain taken with visible-light (RGB) camera installed on UAV. The compressed photographs (JPG format) are pre-processed with the use of parallel computing in order to resize the images. The structure-from-motion (SfM) procedure - herein based on the RunSFM solution - is utilized to generate a non-georeferenced dense point cloud. The subsequent automatic georeferencing procedure comprises two stages: (1) initial registration of the snow-covered dense point cloud using the Helmert transformation, the parameters of which are estimated from camera positions in local (image) and Universal Transverse Mercator (UTM) coordinate systems, (2) final registration of the snow-covered dense point cloud with the iterative closest point (ICP) algorithm applied in respect to a reference snow-free and highly accurate dense point cloud. The second phase is based on the automated ICP application to two subsets of these dense point clouds which include only tall land cover elements, mainly trees. This enables the ICP-based transformation of the source (with snow) dense point cloud into the reference one (snow-free). The two dense point clouds are subsequently interpolated to digital surface models (DSMs), the difference of which forms a numerical map of the estimated snow depth. The procedure is tested on the RGB images taken by the micro fixed-wing UAV in the Izerskie Mountains in southwestern Poland. In addition, a reproducibility test, which compares the above-mentioned procedure with its replica based on modified settings (NIR camera, lower flight altitude, bigger number of images, higher resolution, SfM reconstruction produced with Theia and OpenMVS), is also performed. The estimation is validated against spatially-distributed snow depth measurements. It is found that the method resolves snow depth with a correct order of magnitude. Mean absolute error (MAE) of snow depth estimation varied between 0.33 and 0.43 m, whereas measured snow depths were between 0.24 and 1.06 m (mean of 0.41 m). Medium level of reproducibility is reported, with considerable similarity in statistics of snow depth estimation and only partial (local) agreement between spatial patterns of estimated and measured snow depth fields. In addition, the results show potential for using NIR images in producing realistic estimated snow depth surfaces. (C) 2017 Elsevier B.V. All rights reserved.