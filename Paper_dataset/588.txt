DE cloud computing; CPU; Docker; GPU; Kubernetes
ID TIME
AB Container platforms are increasingly being used to deploy cloud-based services. Nevertheless, many cloud services are also demanding graphics processing units (GPUs) to accelerate different applications that make use of their parallel architecture, such as deep learning or just video processing. Thus, different container technologies, such as Docker and Kubernetes, are implementing GPU support. Some effort is being devoted to design algorithms to schedule applications into heterogeneous computing systems that use CPUs and GPUs together. This article is part of this effort, and we describe how to build a dynamic scheduling platform for Kubernetes that is able to manage the deployment of Docker containers in a heterogeneous cluster, which we call KubCG. This platform implements a new scheduler that optimizes the deployment of new containers by taking into account the Kubernetes Pod timeline and the historical information about the execution of the containers. We have performed different tests to validate this new algorithm, and KubCG was able to reduce the time to complete different tasks down to a 64% of the original time in our different experiments.