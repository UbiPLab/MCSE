DE Fog computing; renewable energy; battery management; reinforcement
   learning; Markov model
ID ENERGY-STORAGE
AB In the last years, Internet is evolving towards the cloud-computing paradigm complemented by fog-computing in order to distribute computing, storage, control, networking resources, and services close to end-user devices as much as possible, while sending heavy jobs to the remote cloud. When fog-computing nodes cannot be powered by the main electric grid, some environmental-friendly solutions, such as the use of solar-or wind-based generators could be adopted. Their relatively unpredictable power output makes it necessary to include an energy storage system in order to provide power, when a peak of work occurs during periods of low-power generation. An optimized management of such an energy storage system in a green fog-computing node is necessary in order to improve the system performance, allowing the system to cope with high job arrival peaks even during low-power generation periods. In this perspective, this paper adopts reinforcement learning to choose a server activation policy that ensures the minimum job loss probability. A case study is presented to show how the proposed system works, and an extensive performance analysis of a fog-computing node highlights the importance of optimizing battery management according to the size of the Renewable-Energy Generator system and the number of available servers.