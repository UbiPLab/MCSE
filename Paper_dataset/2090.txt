AB High computational demands of deep neural networks (DNNs) coupled with their pervasiveness across cloud and loT platforms have led to the emergence of DNN accelerators employing hundreds of processing elements (PE). Most DNN accelerators are optimized for regular mapping of the problems, or dataflows, emanating from dense matrix multiplications in convolutional layers. However, continuous innovations in DNN including myriad layer types/shapes. cross-layer fusion, and sparsity have led to irregular dataflows within accelerators, which introduces severe PE underutilization because of rigid and tightly coupled connections among PEs and buffers. To address this challenge, this paper proposes a communication-centric approach called MAERI for designing DNN accelerators. MAERI's key novelty is a light-weight configurable interconnect connecting all compute and memory elements that enable efficient mapping of both regular and irregular dataflows providing near 100% PE utilization.