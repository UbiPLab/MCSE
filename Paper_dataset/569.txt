DE Convolution neural network (CNN); Deep learning (DL); Quality of service
   (QoS); Social cloud (SC) computing; Etc
AB With the development of multimedia and the popularity of social cloud (SC), Quality of Service (QoS) is used to measure the technical parameters of service delivery. QoS is mostly used for measuring various kinds of multimedia data. Sharing (uploading) on SC has become the daily activity of end-users. As a result of this activity, it provides an open challenge for service providers. As a service provider, the host delivers productive infrastructure, allowing end-users to upload and share their high-quality images. To evaluate the QoS of image compression, we conduct objective QoS techniques to measure the efficiency of image quality and QoS performance of service delivery via uploading /downloading of images on three popular SC, (Facebook, Twitter, and Instagram). These social clouds and image services are compared by the mean, standard deviation (STDEV),mean square error (MSE), and signal-to-noise ratio (SNR). So we can achieve better results about the SC image quality. The results show that Instagram and Facebook compressed images more as compared to Twitter. However, Twitter less supports image formats and provides an acceptable quality of compressed images as compared to others. Therefore, Facebook supports all image file formats and enhanced (QoE) levels of end-users, but Twitter provided the best QoS of compressed images as compared to Instagram. Further, we found that the decrease of MSE and increase of SNR both have a high impact on image resolutions as compared to original image parameters, which has a higher effect on quality. For the specific quality assurance of image tasks acquired for robust automated image analysis research, we are also using deep learning techniques (DLT) to classify the quality of images. We also have identified the opportunity to simplify the Convolutional Neural network (CNN) with smaller resampling grids and making this process more suitable for at least five thousand (5000) of the enormous datasets available in the future.