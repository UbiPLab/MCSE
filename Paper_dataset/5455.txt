DE convolutional neural network; neuroaccelerators; neuroprocessor; object
   detection; deep learning
AB This paper is devoted to a comparative analysis of neural network models based on neuroprocessors. The following neural network models were selected: MobileNetSSD v1, SSD MobileNet v2. As a research task, the authors determined an attempt to compare several platforms that differ in size, computational capabilities and cost: Coral Dev Board, NVIDIA Jetson Nano, Coral USB Accelerator, Neural Compute Stick 2, Raspberry Pi 4. Local data processing offers a number of advantages compared to downloading calculations to a remote server or data center. Firstly, downloading data to remote servers takes a lot of time, as well as additional costs for infrastructure with energy, financial and computer equipment. It also requires high bandwidth and reliability, as data transfer may not be completed in case of a bad signal. Secondly, data transfer can lead to security and privacy issues. Finally, local processing can reduce the amount of data transferred to the cloud, which allows to performing tasks of a higher level.
   The aim of this paper is a comparative analysis of platforms for object recognition tasks (object detection) with MobileNetSSD v1 / v2 models. For training, a cloud service based on the Jupyter Notebook, which gives access to incredibly fast GPUs and TPUs was used. The paper addresses the topic of determining small objects using the example of car detection.
   Based on the study of platforms and models, it was found that the MobileNetSSD v1 model is effective for NVIDIA Jetson Nano by NVIDIA (61FPS), but in turn, the MobileNet v2 SSD model is less efficient (11FPS). Google's Coral Dev Board is more productive than other devices (47.8FPS and 63FPS). Raspberry Pi 4 (0.8FPS and 1.4FPS) turned out to be less effective. Among neuroprocessors, Neural Compute Stick 2 (9FPS and 7.1FPS) showed poor performance.