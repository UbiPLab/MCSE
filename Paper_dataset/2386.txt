DE cloud geodatabase; sponge city; Hadoop; concurrent retrieval; access
ID COLONY CLUSTERING-ALGORITHM; OPTIMIZATION ALGORITHM; BIG DATA; STORAGE;
   SYSTEM; CHINA; WATER; GIS
AB Building a cloud geodatabase for a sponge city is crucial to integrate the geospatial information dispersed in various departments for multi-user high concurrent access and retrieval, high scalability and availability, efficient storage and management. In this study, Hadoop distributed computing framework, including Hadoop distributed file system and MapReduce (mapper and reducer), is firstly designed with a parallel computing framework to process massive spatial data. Then, access control with a series of standard application programming interfaces for different functions is designed, including spatial data storage layer, cloud geodatabase access layer, spatial data access layer and spatial data analysis layer. Subsequently, a retrieval model is designed, including direct addressing via file name, three-level concurrent retrieval and block data retrieval strategies. Main functions are realised, including real-time concurrent access, high-performance computing, communication, massive data storage, efficient retrieval and scheduling decisions on the multi-scale, multi-source and massive spatial data. Finally, the performance of Hadoop cloud geodatabases is validated and compared with that of the Oracle database. The cloud geodatabase for the sponge city can avoid redundant configuration of personnel, hardware and software, support the data transfer, model debugging and application development, and provide accurate, real-time, virtual, intelligent, reliable, elastically scalable, dynamic and on-demand cloud services of the basic and thematic geographic information for the construction and management of the sponge city.