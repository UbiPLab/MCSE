DE Crowd-sourcing; Data processing; Wireless computing; Volunteer computing
ID BIG DATA; PERFORMANCE; ALLOCATION
AB Big-data acquisition and processing is important in developing value driven machine learning applications. This is challenging in compute resource-constrained scenarios. Compute resource-constrained scenarios arise due to low capacity of installed cloud infrastructure and low availability of high speed internet links. These factors limit the ability to process crowd-sourced data to develop machine learning applications. The volunteer computing paradigm is found to be suitable for addressing these challenges. Volunteer computing paradigm makes use of computing nodes provided by users distributed over a geographical area. It leverages on the availability of volunteers with low cost computing entities. This paper proposes the fractionated computing system (FCS) to address the challenges described above. FCS incorporates intelligent compute node selection and uses high performance end-user computing nodes (laptops) to process the crowd-sourced data. The performance of FCS is investigated against the existing method of using cloud servers. Results show that FCS reduces acquisition costs and power consumption by 35% and up to 56.5% on average, respectively. The watt per bit expended in processing crowd-sourced data is also enhanced by up to 98% on average. In addition, the use of FCS enhances memory resources accessible for data processing. Simulations show that increasing memory in modular computing entities by up to 58.7% enhances memory available across network of modular volunteer computing nodes by 0.5 EB. The use of end-user nodes with modular communication subsystems instead of end-user computing nodes with non-modular communication sub-systems enhances channel capacity by 37.5% on average.